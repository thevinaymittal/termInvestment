{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Term Investor predictor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygKPodg3KFi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class BankDataset:\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BankDataset, self).__init__(**kwargs)\n",
        "\n",
        "        # This will be initialised by the load method with all the dataset features\n",
        "        self.X = None\n",
        "\n",
        "        # This will be initialised by the load method with all the dataset classes\n",
        "        self.y = None       \n",
        "\n",
        "        # As name suggests\n",
        "        self.feature_names = [\"age\",\"job\",\"marital\",\"education\",\"default\",\"balance\",\"housing\",\n",
        "                              \"loan\",\"contact\",\"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\"]\n",
        "        self.target_names = [\"no\", \"yes\"]\n",
        "\n",
        "        self.feature_types = [\"num\",\"cat\",\"cat\",\"cat\",\"cat\",\"num\",\"cat\",\n",
        "                              \"cat\",\"cat\",\"num\",\"cat\",\"num\",\"num\",\"num\",\"num\",\"cat\"]\n",
        "        \n",
        "    def preprocess(self, type_, filter=[], apply_scaling=False):  \n",
        "        # filter is for any filtered variables that you dont want\n",
        "\n",
        "        if type_ == \"numerical\": #Just to avoid no nums in standard classifiers\n",
        "            self.feature_encoders = [\n",
        "                                     \n",
        "                None,  \n",
        "                # age\n",
        "\n",
        "                preprocessing.LabelEncoder().fit(\n",
        "                    [\"admin.\", \"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \n",
        "                     \"self-employed\", \"services\", \"student\", \"technician\", \"unemployed\", \"unknown\" ]),  \n",
        "                # job\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([\"divorced\", \"married\",  \"single\"]),  \n",
        "                # marital\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([\"primary\", \"secondary\", \"tertiary\", \"unknown\"]),\n",
        "                # education\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([\"no\", \"yes\"]),\n",
        "                # default\n",
        "                \n",
        "                None,\n",
        "                # balance\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([\"no\", \"yes\"]),  \n",
        "                # housing\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([\"no\", \"yes\"]),  \n",
        "                # loan\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([\"cellular\",  \"telephone\", \"unknown\"]),  \n",
        "                # contact\n",
        "                \n",
        "                None,\n",
        "                # day\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([ \"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\",\"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]),\n",
        "                # month\n",
        "                \n",
        "                None, \n",
        "                # duration\n",
        "                \n",
        "                None,\n",
        "                # campaign\n",
        "                \n",
        "                None,\n",
        "                # pdays\n",
        "                \n",
        "                None, \n",
        "                # previous\n",
        "                \n",
        "                preprocessing.LabelEncoder().fit([ \"failure\", \"other\", \"success\", \"unknown\"]),\n",
        "                # poutcome\n",
        "            \n",
        "            ]\n",
        "        elif type_ == \"one-hot\": #Just to have proper flow of non nums labels\n",
        "            self.feature_encoders = [\n",
        "                None,  # age\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit(\n",
        "                    [\"admin.\", \"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \n",
        "                     \"self-employed\", \"services\", \"student\", \"technician\", \"unemployed\", \"unknown\" ]\n",
        "                    ),  preprocessing.OneHotEncoder(n_values=12, sparse=False)),\n",
        "                # job\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([\"divorced\", \"married\",  \"single\"]), preprocessing.OneHotEncoder(n_values=3, sparse=False)),  \n",
        "                # marital\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([\"primary\", \"secondary\", \"tertiary\", \"unknown\"]), preprocessing.OneHotEncoder(n_values=4, sparse=False)),\n",
        "                # education\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([\"no\", \"yes\"])),\n",
        "                # default\n",
        "\n",
        "\n",
        "                None,\n",
        "                # balance\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([\"no\", \"yes\"])),  \n",
        "                # housing\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([\"no\", \"yes\"])),  \n",
        "                # loan\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([\"cellular\",  \"telephone\", \"unknown\"]), preprocessing.OneHotEncoder(n_values=3, sparse=False)),\n",
        "                # contact\n",
        "\n",
        "\n",
        "                None,\n",
        "                #day\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([ \"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\",\"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
        "                    ), preprocessing.OneHotEncoder(n_values=12, sparse=False)),\n",
        "                # month\n",
        "\n",
        "\n",
        "                None, \n",
        "                # duration\n",
        "\n",
        "\n",
        "                None,\n",
        "                # campaign\n",
        "\n",
        "\n",
        "                None,\n",
        "                # pdays\n",
        "\n",
        "\n",
        "                None, \n",
        "                # previous\n",
        "\n",
        "\n",
        "                (preprocessing.LabelEncoder().fit([ \"failure\", \"other\", \"success\", \"unknown\"]), preprocessing.OneHotEncoder(n_values=4, sparse=False))\n",
        "                # poutcome\n",
        "\n",
        "\n",
        "            ]\n",
        "        else:\n",
        "            raise ValueError(\"Unable to load feature encoders for type {}\".format(type_))\n",
        "\n",
        "        self.class_encoder = preprocessing.LabelBinarizer().fit([\"no\", \"yes\"])\n",
        "\n",
        "        num_features = self.X.shape[1]\n",
        "        print(\"Number of features is {}\".format(num_features))\n",
        "        num_instances = self.X.shape[0]\n",
        "        print(\"Number of instances is {}\".format(num_instances))\n",
        "        one_hot_applied = False\n",
        "        new_features = []\n",
        "\n",
        "        for f_id in [x for x in range(num_features) if not x in filter]:\n",
        "            # convert them to integers\n",
        "            if self.feature_encoders[f_id] is None:\n",
        "                if type_ == \"one-hot\":\n",
        "                    new_features.append(np.expand_dims(self.X[:, f_id].astype(np.float32), -1))\n",
        "                else:\n",
        "                    new_features.append(self.X[:, f_id].astype(np.float32))\n",
        "            else:\n",
        "                # apply in sequence the preprocessors\n",
        "                if isinstance(self.feature_encoders[f_id], (list, tuple)):\n",
        "                    one_hot_applied = True\n",
        "                    temp = self.feature_encoders[f_id][0].transform(np.expand_dims(self.X[:, f_id], -1))\n",
        "                    new_features.append(self.feature_encoders[f_id][1].fit_transform(np.expand_dims(temp, -1)))\n",
        "                else:\n",
        "                    temp = self.feature_encoders[f_id].transform(np.expand_dims(self.X[:, f_id], -1))\n",
        "                    new_features.append(np.expand_dims(temp, -1))\n",
        "\n",
        "        if one_hot_applied or type_ == \"one-hot\":\n",
        "            self.X = np.concatenate(new_features, -1)\n",
        "            print(\"Selected\")\n",
        "        else:\n",
        "            self.X = np.array(self.X)\n",
        "        # apply max abs scaling (useful for 1-hot representations)\n",
        "        if apply_scaling:\n",
        "            self.scaler = MaxAbsScaler().fit(self.X)\n",
        "            self.X = self.scaler.transform(self.X)\n",
        "        print(type(self.y))\n",
        "        self.y = np.array(self.class_encoder.transform(self.y))\n",
        "        self.y = self.y.squeeze(-1)\n",
        "        print(type(self.y))\n",
        "        print(\"Dataset correctly preprocessed\")\n",
        "        \n",
        "    def load(self, filename):\n",
        "        \"\"\"\n",
        "        Loads the data from the specified file \n",
        "        \"\"\"\n",
        "        print(\"Loading bank dataset from file {}\".format(filename))\n",
        "        # we open the file in read mode\n",
        "        with open(filename) as in_file:\n",
        "            self.X = []\n",
        "            self.y = []\n",
        "            \n",
        "            for line in in_file:\n",
        "                # Reminder: each line is in composed by values seperated by commas\n",
        "                # e.g., 36,technician,married,tertiary,no,4596,yes,no,cellular,8,oct,234,2,175,2,success,yes\n",
        "                values = line.strip().split(\",\")\n",
        "                \n",
        "                # we just make sure that we read a valid line\n",
        "                if values and values[0] != '' and \"?\" not in values:\n",
        "                    curr_X = values[:-1]\n",
        "                    # we extract the class value for the current example\n",
        "                    curr_y = values[-1]\n",
        "\n",
        "                    # we store the current values by appending them to X and Y\n",
        "                    self.X.append(curr_X)\n",
        "                    self.y.append(curr_y)\n",
        "            \n",
        "            print(\"Dataset correctly loaded\")\n",
        "            self.X = np.array(self.X)\n",
        "            self.y = np.array(self.y)\n",
        "    \n",
        "    def report(self):\n",
        "    \n",
        "        \"\"\"\n",
        "        Prints relevant information about the dataset \n",
        "        \"\"\"\n",
        "        # we assume that both X and Y have been correctly loaded\n",
        "        if self.X is None and self.y is None:\n",
        "            raise ValueError(\"Remember to call 'load' to load the dataset!\")\n",
        "        \n",
        "        print(\"Num. examples: {}\".format(str(self.X.shape[0])))\n",
        "        print(\"Num. features: {}\".format(str(self.X.shape[1])))\n",
        "        \n",
        "        # TODO: Implement printing of mean/variance for numerical and mode for categorical values.\n",
        "        \n",
        "        # print(\"calculating\")\n",
        "        num_column = []\n",
        "        cat_column = []\n",
        "        for i,j in enumerate(self.feature_types):\n",
        "          if j=='num':\n",
        "            num_column.append(self.X[:,i])\n",
        "          else:\n",
        "            cat_column.append(self.X[:,i])\n",
        "\n",
        "        num_column = (np.array(num_column)).transpose()\n",
        "        num_column = np.asarray(num_column).astype(np.float64)\n",
        "        cat_column = (np.array(cat_column)).transpose()    \n",
        "        print(num_column.shape)\n",
        "        print(self.X.shape)\n",
        "        print(self.X[:,0]==num_column[:,0])\n",
        "                      \n",
        "\n",
        "        mean = np.mean(num_column, axis = 0)\n",
        "        std  = np.std (num_column, axis = 0)\n",
        "        var  = np.var (num_column, axis = 0)\n",
        "\n",
        "        from scipy import stats\n",
        "        m = stats.mode(cat_column, axis = 0)\n",
        "        mode = m[0][0]\n",
        "\n",
        "        count_mean = 0\n",
        "        count_mode = 0\n",
        "        for i in (self.feature_types):\n",
        "\n",
        "          if i=='num':\n",
        "            \n",
        "            print('')\n",
        "            print(\"The mean of the column  \"+ \"''\"+str(self.feature_names[count_mean+count_mode])+\"''\"+'   is:')\n",
        "            print(mean[count_mean])\n",
        "            print(\"The Standard Deviation\" +' is:')\n",
        "            print(std[count_mean])\n",
        "            print(\"& The Variance\" +' is:')\n",
        "            print(var[count_mean])\n",
        "            count_mean+=1\n",
        "            print('')\n",
        "            \n",
        "          else:\n",
        "            print('')\n",
        "            print(\"The mode of the column  \"+ \"''\"+self.feature_names[count_mode+count_mean] +\"''\"+'   is:')\n",
        "            print(mode[count_mode])\n",
        "            count_mode+=1\n",
        "\n",
        "\n",
        "        # TODO: Implement outputing plot histograms for each feature\n",
        "        for i in (self.feature_names):\n",
        "          print('')\n",
        "          plt.figure(figsize=(20,8))\n",
        "          plt.title('Histogram of '+str(i))\n",
        "          plt.xlabel('Categories')\n",
        "          plt.ylabel('Frequency')\n",
        "          #plt.axis([40, 160, 0, 0.03])\n",
        "          plt.hist(self.X[:,(self.feature_names).index(i)])\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(filename, preprocess_onehot=False, apply_scaling=False):\n",
        "    \n",
        "    dataset = BankDataset()\n",
        "\n",
        "    dataset.load(filename)\n",
        "    if preprocess_onehot:\n",
        "        dataset.preprocess(\"one-hot\", apply_scaling=apply_scaling)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Simply calls report() on the corresponding dataset\n",
        "def analyze(dataset,name= None):\n",
        "    \n",
        "    c = load_dataset(filename=dataset)\n",
        "    c.report()\n",
        "\n",
        "\n",
        "def decision_trees(train_dataset, dev_dataset, test_dataset):\n",
        "    \n",
        "    #  1. Implement Decision Tree classifier \n",
        "    #  2. Then predict on train/dev and compute accuracy.\n",
        "    #  3. To run hyperparameter tuning on dev set print out the accuracies versus depth values and select best\n",
        "    #  hyperparameter specification\n",
        "    #  4. Finally, report accuracy on test dataset\n",
        "\n",
        "    data  = train_dataset\n",
        "    depth = 1\n",
        "    c = load_dataset(filename=data, preprocess_onehot=True)\n",
        "    DTC1 = DecisionTreeClassifier(random_state = 1,\n",
        "                               max_depth=depth)\n",
        "    DTC1.fit(c.X, c.y)\n",
        "    print(\"The accuracy over train dataset is \"+ str(DTC1.score( c.X, c.y)*100)+\" %\" )\n",
        "    \n",
        "    depth = 2\n",
        "    DTC2 = DecisionTreeClassifier(random_state = 1,\n",
        "                               max_depth=depth)\n",
        "    DTC2.fit(c.X, c.y)\n",
        "    print(\"The accuracy over train dataset is \"+ str(DTC2.score( c.X, c.y)*100)+\" %\" )\n",
        "\n",
        "\n",
        "\n",
        "def kNN(train_dataset, dev_dataset, test_dataset):\n",
        "\n",
        "    #  1. Implement kNN classifier and train with k=1,2.\n",
        "    #  2. Then predict on train/dev and compute accuracy.\n",
        "    #  3. To run hyperparameter tuning on dev set print out the accuracies versus k values and select best k\n",
        "    #  4. Finally, report accuracy on test dataset\n",
        "\n",
        "    if train_dataset:\n",
        "            \n",
        "          data  = train_dataset\n",
        "          k = 1\n",
        "          c = load_dataset(filename=data, preprocess_onehot=True)\n",
        "          knn = KNeighborsClassifier(n_neighbors=k, weights=\"uniform\")\n",
        "          knn.fit(c.X, c.y)\n",
        "          print(\"The accuracy over train dataset is \"+ str(knn.score( c.X, c.y)*100)+\" %\" )\n",
        "\n",
        "    elif dev_dataset:\n",
        "      \n",
        "          data  = dev_dataset\n",
        "          k = 1\n",
        "          c = load_dataset(filename=data, preprocess_onehot=True)\n",
        "          knn = KNeighborsClassifier(n_neighbors=k, weights=\"uniform\")\n",
        "          knn.fit(c.X, c.y)\n",
        "          print(\"The accuracy over dev dataset is \"+ str(knn.score( c.X, c.y)*100)+\" %\" )\n",
        "    elif test_dataset:\n",
        "      \n",
        "          data  = dev_dataset\n",
        "          k = 1\n",
        "          c = load_dataset(filename=data, preprocess_onehot=True)\n",
        "          knn = KNeighborsClassifier(n_neighbors=k, weights=\"uniform\")\n",
        "          knn.fit(c.X, c.y)\n",
        "          print(\"The accuracy over dev dataset is \"+ str(knn.score( c.X, c.y)*100)+\" %\" )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}